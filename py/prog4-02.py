# -*- coding: utf-8 -*-
"""prog3-16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s2smNYuR-3KMu2LDpcvI7Qc3nDcuP3xa
"""

from google.colab import files
files.upload() # kaggle.jsonをアップロード
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectKBest
# 相互情報量を計算するメソッドをインポート
from sklearn.feature_selection import mutual_info_classif

# データの準備
def prepare():
    !kaggle datasets download -d pmenshih/kpmi-mbti-mod-test 
    !unzip kpmi-mbti-mod-test.zip

# 前処理（使用する項目の絞り込み、正規化）
def preprocess():
    # MBTI診断データを読込み
    df = pd.read_csv('kpmi_data.csv', sep=';')
    # 現在の職業に満足しているかどうか(yes:1, no:0)
    y = df.loc[:, 'satisfied'].values
    # 使用する特徴量（MBTIのスコア)
    scales = ['scale_e','scale_i','scale_s','scale_n',
              'scale_t','scale_f','scale_j','scale_p']
    df = pd.DataFrame(df.loc[:,scales], columns=scales)
    print(df)
    X = df.loc[:, df.columns.values].values
    X_train, X_test, y_train, y_test = train_test_split(X, y,
   random_state=0, train_size=0.9)
    return X_train, X_test, y_train, y_test, scales

# ランダムフォレストで分類評価
def predict_satisfaction(X_train, X_test, y_train, y_test):
    clf = RandomForestClassifier(max_depth=4, random_state=2)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    print('Accuracy = {:.3f}'.format(accuracy_score(
  y_test, y_pred)))
    labels = ['no', 'yes']
    print(classification_report(y_test, y_pred,
   target_names=labels))
    
# MI (相互情報量)を用いて特徴選択
def select_feature_by_MI(X_train, X_test, y_train, y_test, scales, n_features): 
    # n_featuers 個の特徴量を選択
    selecter = SelectKBest(
        mutual_info_classif, k=n_features).fit(
                     X_train, y_train)

    sel_features = []
    selected_feature = selecter.get_support()
    for i in range(len(selected_feature)):
        if selected_feature[i]:
            print('Selected Feature - {}'.format( \
                                          scales[i])) 
            sel_features.append(scales[i])
    trdf = pd.DataFrame(X_train, columns=scales) 
    tedf = pd.DataFrame(X_test, columns=scales)
    X_train = trdf.loc[:, sel_features].values
    X_test = tedf.loc[:, sel_features].values
    return X_train, X_test

def main():
    prepare()
    X_train, X_test, y_train, y_test, scales = preprocess()
    print('- 特徴選択無し [%d個の特徴量] -' % len(scales))
    predict_satisfaction(X_train, X_test, y_train, y_test)
    n_features = 3
    print('- MIによる特徴選択 [%d個の特徴量] -' % n_features)
    X_train, X_test = select_feature_by_MI(X_train, X_test,
   y_train, y_test, scales, n_features)
    predict_satisfaction(X_train, X_test, y_train, y_test)

if __name__ == '__main__':
    main()